{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUnQccLefUdyAFS0JBWXDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andgreenman/OpenAlex-to-Scopus-crosswalk/blob/main/Crosswalk_OpenAlex_to_Scopus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script takes an exported search results list from the OpenAlex website, which cannot normally be loaded into VOSViewer directly, and coverts it to the format of a Scopus export. Custom filtering of the data exported from OpenAlex should be performed before this step."
      ],
      "metadata": {
        "id": "N8UmlyKG3EqC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLcgL9LE1JKV"
      },
      "outputs": [],
      "source": [
        "pip install requests-cache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "import requests_cache\n",
        "from requests.exceptions import HTTPError"
      ],
      "metadata": {
        "id": "6Fp86cmm1Ode"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = r'' #put csv file path string here"
      ],
      "metadata": {
        "id": "fh28KvMh1Pvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "works = pd.read_csv(file, header=0)\n",
        "df = pd.DataFrame(works)\n",
        "df.dropna(subset='publication_year') # OpenAlex exports sometimes have random junk rows, usually this catches them"
      ],
      "metadata": {
        "id": "MGTpLz-p1Q6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "take_columns = ['authorships.author.display_name',\n",
        "                'authorships.author.id',\n",
        "                'title',\n",
        "                'publication_year',\n",
        "                'primary_location.source.display_name',\n",
        "                'biblio.volume',\n",
        "                'biblio.issue',\n",
        "                'biblio.first_page',\n",
        "                'biblio.last_page',\n",
        "                'cited_by_count',\n",
        "                'doi',\n",
        "                'ids.openalex',\n",
        "                'authorships.raw_affiliation_strings',\n",
        "                'abstract',\n",
        "                'topics.display_name',\n",
        "                'keywords.display_name',\n",
        "                'grants.funder_display_name',\n",
        "                'referenced_works',\n",
        "                'primary_location.source.host_organization_name',\n",
        "                'primary_location.source.issn_l',\n",
        "                'ids.pmcid',\n",
        "                'language',\n",
        "                'type',\n",
        "                'primary_location.version',\n",
        "                'open_access.oa_status',\n",
        "                'id']\n",
        "\n",
        "scopus_columns = ['Authors',\n",
        "                'Author(s) ID',\n",
        "                'Title',\n",
        "                'Year',\n",
        "                'Source title',\n",
        "                'Volume',\n",
        "                'Issue',\n",
        "                'Page start',\n",
        "                'Page end',\n",
        "                'Cited by',\n",
        "                'DOI',\n",
        "                'Link',\n",
        "                'Affiliations',\n",
        "                'Abstract',\n",
        "                'Author Keywords',\n",
        "                'Index Keywords',\n",
        "                'Funding Details',\n",
        "                'References',\n",
        "                'Publisher',\n",
        "                'ISSN',\n",
        "                'PubMed ID',\n",
        "                'Language of Original Document',\n",
        "                'Document Type',\n",
        "                'Publication Stage',\n",
        "                'Open Access',\n",
        "                'EID']\n",
        "\n",
        "rename_dict = dict(zip(take_columns, scopus_columns))"
      ],
      "metadata": {
        "id": "TMDiyAJn1Uh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus = df.loc[:, take_columns]"
      ],
      "metadata": {
        "id": "NXWxdX6x1WXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus.rename(columns=rename_dict, inplace=True)\n",
        "df.columns = df.columns.str.strip()"
      ],
      "metadata": {
        "id": "jxd9J_hT1Xyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_modify = ['Authors', 'Author(s) ID', 'Affiliations', 'Author Keywords', 'Index Keywords', 'Funding Details']"
      ],
      "metadata": {
        "id": "GpGor8281Y91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus[columns_to_modify] = dfscopus[columns_to_modify].apply(lambda x: x.str.replace(r'\\|', '; ', regex=True))\n",
        "\n",
        "dfscopus['DOI'] = dfscopus['DOI'].str.removeprefix('https://doi.org/')\n",
        "\n",
        "dfscopus['EID'] = dfscopus['EID'].str.removeprefix('https://openalex.org/')\n",
        "\n",
        "dfscopus['Author(s) ID'] = dfscopus['Author(s) ID'].apply(lambda ids: ';'.join([id.replace('https://openalex.org/', '') for id in ids.split(';')]))\n",
        "\n",
        "dfscopus['References'] = dfscopus['References'].apply(lambda references: '|'.join([reference.replace('https://openalex.org/', '') for reference in str(references).split('|')]) if not isinstance(references, float) else references)"
      ],
      "metadata": {
        "id": "gJSFnWJz1bU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus.insert(1, 'Author full names', '')\n",
        "dfscopus.insert(8, 'Art. No.', '')\n",
        "dfscopus.insert(11, 'Page count', '')\n",
        "dfscopus.insert(16, 'Authors with affiliations', '')\n",
        "dfscopus.insert(21, 'Funding Texts', '')\n",
        "dfscopus.insert(23, 'Correspondence Address', '')\n",
        "dfscopus.insert(24, 'Editors', '')\n",
        "dfscopus.insert(27, 'ISBN', '')\n",
        "dfscopus.insert(28, 'CODEN', '')\n",
        "dfscopus.insert(31, 'Abbreviated Source Title', '')\n",
        "dfscopus.insert(35, 'Source', 'OpenAlex')"
      ],
      "metadata": {
        "id": "J7s_rBvd1cLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def name_fl_to_li(name):\n",
        "  name_parts = name.split(' ')\n",
        "  temp = '.'.join([name_parts[i][0] for i in range (0, len(name_parts) - 1)])\n",
        "  if temp == '':\n",
        "      return (name_parts[-1])\n",
        "  else:\n",
        "      return (name_parts[-1] + ', ' + temp +'.')"
      ],
      "metadata": {
        "id": "RMI1Q77p1dyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_authors(authors):\n",
        "    author_list = authors.split(';')\n",
        "    formatted_authors = []\n",
        "    for author in author_list:\n",
        "        author = author.strip()\n",
        "        formatted_authors.append(name_fl_to_li(author))\n",
        "\n",
        "    return '; '.join(formatted_authors)"
      ],
      "metadata": {
        "id": "VyZy5TmX1fyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus['Authors'] = dfscopus['Authors'].apply(lambda x: process_authors(x) if pd.notnull(x) else '')"
      ],
      "metadata": {
        "id": "ggw9GGhW1gUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coding: utf8\n",
        "\n",
        "languages = [\n",
        "    ('aa', 'Afar'),\n",
        "    ('ab', 'Abkhazian'),\n",
        "    ('af', 'Afrikaans'),\n",
        "    ('ak', 'Akan'),\n",
        "    ('sq', 'Albanian'),\n",
        "    ('am', 'Amharic'),\n",
        "    ('ar', 'Arabic'),\n",
        "    ('an', 'Aragonese'),\n",
        "    ('hy', 'Armenian'),\n",
        "    ('as', 'Assamese'),\n",
        "    ('av', 'Avaric'),\n",
        "    ('ae', 'Avestan'),\n",
        "    ('ay', 'Aymara'),\n",
        "    ('az', 'Azerbaijani'),\n",
        "    ('ba', 'Bashkir'),\n",
        "    ('bm', 'Bambara'),\n",
        "    ('eu', 'Basque'),\n",
        "    ('be', 'Belarusian'),\n",
        "    ('bn', 'Bengali'),\n",
        "    ('bh', 'Bihari languages'),\n",
        "    ('bi', 'Bislama'),\n",
        "    ('bo', 'Tibetan'),\n",
        "    ('bs', 'Bosnian'),\n",
        "    ('br', 'Breton'),\n",
        "    ('bg', 'Bulgarian'),\n",
        "    ('my', 'Burmese'),\n",
        "    ('ca', 'Catalan; Valencian'),\n",
        "    ('cs', 'Czech'),\n",
        "    ('ch', 'Chamorro'),\n",
        "    ('ce', 'Chechen'),\n",
        "    ('zh', 'Chinese'),\n",
        "    ('cu', 'Church Slavic; Old Slavonic; Church Slavonic; Old Bulgarian; Old Church Slavonic'),\n",
        "    ('cv', 'Chuvash'),\n",
        "    ('kw', 'Cornish'),\n",
        "    ('co', 'Corsican'),\n",
        "    ('cr', 'Cree'),\n",
        "    ('cy', 'Welsh'),\n",
        "    ('cs', 'Czech'),\n",
        "    ('da', 'Danish'),\n",
        "    ('de', 'German'),\n",
        "    ('dv', 'Divehi; Dhivehi; Maldivian'),\n",
        "    ('nl', 'Dutch; Flemish'),\n",
        "    ('dz', 'Dzongkha'),\n",
        "    ('el', 'Greek, Modern (1453-)'),\n",
        "    ('en', 'English'),\n",
        "    ('eo', 'Esperanto'),\n",
        "    ('et', 'Estonian'),\n",
        "    ('eu', 'Basque'),\n",
        "    ('ee', 'Ewe'),\n",
        "    ('fo', 'Faroese'),\n",
        "    ('fa', 'Persian'),\n",
        "    ('fj', 'Fijian'),\n",
        "    ('fi', 'Finnish'),\n",
        "    ('fr', 'French'),\n",
        "    ('fy', 'Western Frisian'),\n",
        "    ('ff', 'Fulah'),\n",
        "    ('Ga', 'Georgian'),\n",
        "    ('de', 'German'),\n",
        "    ('gd', 'Gaelic; Scottish Gaelic'),\n",
        "    ('ga', 'Irish'),\n",
        "    ('gl', 'Galician'),\n",
        "    ('gv', 'Manx'),\n",
        "    ('el', 'Greek, Modern (1453-)'),\n",
        "    ('gn', 'Guarani'),\n",
        "    ('gu', 'Gujarati'),\n",
        "    ('ht', 'Haitian; Haitian Creole'),\n",
        "    ('ha', 'Hausa'),\n",
        "    ('he', 'Hebrew'),\n",
        "    ('hz', 'Herero'),\n",
        "    ('hi', 'Hindi'),\n",
        "    ('ho', 'Hiri Motu'),\n",
        "    ('hr', 'Croatian'),\n",
        "    ('hu', 'Hungarian'),\n",
        "    ('hy', 'Armenian'),\n",
        "    ('ig', 'Igbo'),\n",
        "    ('is', 'Icelandic'),\n",
        "    ('io', 'Ido'),\n",
        "    ('ii', 'Sichuan Yi; Nuosu'),\n",
        "    ('iu', 'Inuktitut'),\n",
        "    ('ie', 'Interlingue; Occidental'),\n",
        "    ('ia', 'Interlingua (International Auxiliary Language Association)'),\n",
        "    ('id', 'Indonesian'),\n",
        "    ('ik', 'Inupiaq'),\n",
        "    ('is', 'Icelandic'),\n",
        "    ('it', 'Italian'),\n",
        "    ('jv', 'Javanese'),\n",
        "    ('ja', 'Japanese'),\n",
        "    ('kl', 'Kalaallisut; Greenlandic'),\n",
        "    ('kn', 'Kannada'),\n",
        "    ('ks', 'Kashmiri'),\n",
        "    ('ka', 'Georgian'),\n",
        "    ('kr', 'Kanuri'),\n",
        "    ('kk', 'Kazakh'),\n",
        "    ('km', 'Central Khmer'),\n",
        "    ('ki', 'Kikuyu; Gikuyu'),\n",
        "    ('rw', 'Kinyarwanda'),\n",
        "    ('ky', 'Kirghiz; Kyrgyz'),\n",
        "    ('kv', 'Komi'),\n",
        "    ('kg', 'Kongo'),\n",
        "    ('ko', 'Korean'),\n",
        "    ('kj', 'Kuanyama; Kwanyama'),\n",
        "    ('ku', 'Kurdish'),\n",
        "    ('lo', 'Lao'),\n",
        "    ('la', 'Latin'),\n",
        "    ('lv', 'Latvian'),\n",
        "    ('li', 'Limburgan; Limburger; Limburgish'),\n",
        "    ('ln', 'Lingala'),\n",
        "    ('lt', 'Lithuanian'),\n",
        "    ('lb', 'Luxembourgish; Letzeburgesch'),\n",
        "    ('lu', 'Luba-Katanga'),\n",
        "    ('lg', 'Ganda'),\n",
        "    ('mk', 'Macedonian'),\n",
        "    ('mh', 'Marshallese'),\n",
        "    ('ml', 'Malayalam'),\n",
        "    ('mi', 'Maori'),\n",
        "    ('mr', 'Marathi'),\n",
        "    ('ms', 'Malay'),\n",
        "    ('Mi', 'Micmac'),\n",
        "    ('mk', 'Macedonian'),\n",
        "    ('mg', 'Malagasy'),\n",
        "    ('mt', 'Maltese'),\n",
        "    ('mn', 'Mongolian'),\n",
        "    ('mi', 'Maori'),\n",
        "    ('ms', 'Malay'),\n",
        "    ('my', 'Burmese'),\n",
        "    ('na', 'Nauru'),\n",
        "    ('nv', 'Navajo; Navaho'),\n",
        "    ('nr', 'Ndebele, South; South Ndebele'),\n",
        "    ('nd', 'Ndebele, North; North Ndebele'),\n",
        "    ('ng', 'Ndonga'),\n",
        "    ('ne', 'Nepali'),\n",
        "    ('nl', 'Dutch; Flemish'),\n",
        "    ('nn', 'Norwegian Nynorsk; Nynorsk, Norwegian'),\n",
        "    ('nb', 'Bokmål, Norwegian; Norwegian Bokmål'),\n",
        "    ('no', 'Norwegian'),\n",
        "    ('oc', 'Occitan (post 1500)'),\n",
        "    ('oj', 'Ojibwa'),\n",
        "    ('or', 'Oriya'),\n",
        "    ('om', 'Oromo'),\n",
        "    ('os', 'Ossetian; Ossetic'),\n",
        "    ('pa', 'Panjabi; Punjabi'),\n",
        "    ('fa', 'Persian'),\n",
        "    ('pi', 'Pali'),\n",
        "    ('pl', 'Polish'),\n",
        "    ('pt', 'Portuguese'),\n",
        "    ('ps', 'Pushto; Pashto'),\n",
        "    ('qu', 'Quechua'),\n",
        "    ('rm', 'Romansh'),\n",
        "    ('ro', 'Romanian; Moldavian; Moldovan'),\n",
        "    ('ro', 'Romanian; Moldavian; Moldovan'),\n",
        "    ('rn', 'Rundi'),\n",
        "    ('ru', 'Russian'),\n",
        "    ('sg', 'Sango'),\n",
        "    ('sa', 'Sanskrit'),\n",
        "    ('si', 'Sinhala; Sinhalese'),\n",
        "    ('sk', 'Slovak'),\n",
        "    ('sk', 'Slovak'),\n",
        "    ('sl', 'Slovenian'),\n",
        "    ('se', 'Northern Sami'),\n",
        "    ('sm', 'Samoan'),\n",
        "    ('sn', 'Shona'),\n",
        "    ('sd', 'Sindhi'),\n",
        "    ('so', 'Somali'),\n",
        "    ('st', 'Sotho, Southern'),\n",
        "    ('es', 'Spanish; Castilian'),\n",
        "    ('sq', 'Albanian'),\n",
        "    ('sc', 'Sardinian'),\n",
        "    ('sr', 'Serbian'),\n",
        "    ('ss', 'Swati'),\n",
        "    ('su', 'Sundanese'),\n",
        "    ('sw', 'Swahili'),\n",
        "    ('sv', 'Swedish'),\n",
        "    ('ty', 'Tahitian'),\n",
        "    ('ta', 'Tamil'),\n",
        "    ('tt', 'Tatar'),\n",
        "    ('te', 'Telugu'),\n",
        "    ('tg', 'Tajik'),\n",
        "    ('tl', 'Tagalog'),\n",
        "    ('th', 'Thai'),\n",
        "    ('bo', 'Tibetan'),\n",
        "    ('ti', 'Tigrinya'),\n",
        "    ('to', 'Tonga (Tonga Islands)'),\n",
        "    ('tn', 'Tswana'),\n",
        "    ('ts', 'Tsonga'),\n",
        "    ('tk', 'Turkmen'),\n",
        "    ('tr', 'Turkish'),\n",
        "    ('tw', 'Twi'),\n",
        "    ('ug', 'Uighur; Uyghur'),\n",
        "    ('uk', 'Ukrainian'),\n",
        "    ('ur', 'Urdu'),\n",
        "    ('uz', 'Uzbek'),\n",
        "    ('ve', 'Venda'),\n",
        "    ('vi', 'Vietnamese'),\n",
        "    ('vo', 'Volapük'),\n",
        "    ('cy', 'Welsh'),\n",
        "    ('wa', 'Walloon'),\n",
        "    ('wo', 'Wolof'),\n",
        "    ('xh', 'Xhosa'),\n",
        "    ('yi', 'Yiddish'),\n",
        "    ('yo', 'Yoruba'),\n",
        "    ('za', 'Zhuang; Chuang'),\n",
        "    ('zh', 'Chinese'),\n",
        "    ('zu', 'Zulu')\n",
        "]\n",
        "\n",
        "language_dict = dict(languages)"
      ],
      "metadata": {
        "id": "xW3qnv3Q1iWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus.loc[:, 'Language of Original Document'] = dfscopus['Language of Original Document'].map(language_dict)"
      ],
      "metadata": {
        "id": "4-kDAW_q1jrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = requests_cache.CachedSession()"
      ],
      "metadata": {
        "id": "LFh7MJax1lAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_batched_references(referenced_works, batch_size=50):\n",
        "    if pd.isna(referenced_works):\n",
        "        return 'No references found'\n",
        "\n",
        "    work_ids = referenced_works.split('|')\n",
        "    batches = [work_ids[i:i + batch_size] for i in range(0, len(work_ids), batch_size)]\n",
        "\n",
        "    details_list = []\n",
        "\n",
        "    for batch in batches:\n",
        "        batch_query = '|'.join(batch)\n",
        "        url = f\"https://api.openalex.org/works?filter=openalex:{batch_query}&per-page=50\"\n",
        "\n",
        "        try:\n",
        "            response = s.get(url)\n",
        "            response.raise_for_status()\n",
        "            works_data = response.json().get('results', [])\n",
        "\n",
        "            for work in works_data:\n",
        "                authors = ', '.join([process_authors(auth['author']['display_name']) for auth in work.get('authorships', [])])\n",
        "                title = work.get('title', 'No title found')\n",
        "                publication_title = work.get('primary_location', {}).get('source', {}).get('display_name', 'No publication title found')\n",
        "                publication_date = work.get('publication_year', 'No publication date found')\n",
        "                details_list.append(f\"{authors}, {title}, {publication_title}, {publication_date}\")\n",
        "\n",
        "        except requests.exceptions.HTTPError as http_err:\n",
        "            print(f\"HTTP error occurred: {http_err} for batch: {batch_query}\")\n",
        "        except Exception as err:\n",
        "            print(f\"Other error occurred: {err}\")\n",
        "\n",
        "    return '; '.join(details_list)"
      ],
      "metadata": {
        "id": "_3sHEWet1upL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus['References'] = dfscopus['References'].apply(fetch_batched_references)"
      ],
      "metadata": {
        "id": "uVACqdCv1vdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '' #put filename here\n",
        "\n",
        "date = datetime.datetime.today().strftime('%Y-%m-%d')"
      ],
      "metadata": {
        "id": "BTfyfSRg2CwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfscopus.to_csv(date + '_' + filename, index=False)"
      ],
      "metadata": {
        "id": "Qpt8peWa1w4j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}